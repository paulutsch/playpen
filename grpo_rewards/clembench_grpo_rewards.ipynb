{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# clembench_grpo_rewards.py\n# Reward functions for GRPO on clembench-style prompts/games.\n# Compatible with TRL GRPOTrainer (main + v0.21 style).\n#\n# ->Each function returns one float per completion in range [-1,1].\n# ->They try to parse needed context from kwargs[\"prompts\"] (if provided) or from extra kwargs like target/clue/feedback. When not available, they fall back to format/compliance rewards.\n\n#every function gives:\n    #format rewards\n    #content rewards\n    #penalizing errors\n\nimport re\nimport math\nfrom typing import List, Dict, Any\n\n# ------------------------------ small utils ------------------------------\n\nORD2IDX = {\n    \"first\": 0, \"1st\": 0, \"one\": 0, \"1\": 0, \"top\": 0, \"leftmost\": 0,\n    \"second\": 1, \"2nd\": 1, \"two\": 1, \"2\": 1,\n    \"third\": 2, \"3rd\": 2, \"three\": 2, \"3\": 2, \"middle\": 2, \"center\": 2, \"centre\": 2,\n    \"fourth\": 3, \"4th\": 3, \"four\": 3, \"4\": 3,\n    \"fifth\": 4, \"5th\": 4, \"five\": 4, \"5\": 4, \"last\": 4, \"bottom\": 4, \"rightmost\": 4,\n}\n\n#circumvent format issues (expected: list, dict, ...) transforming everything to text\ndef _as_text(sample):\n    \"\"\"Convert a TRL completion (string or list[{'content': str}]) to plain text.\"\"\"\n    if isinstance(sample, str):\n        return sample\n    if isinstance(sample, dict) and \"content\" in sample:\n        return sample[\"content\"]\n    if isinstance(sample, list):\n        # typical chat form: a list of messages; we take the assistant's content if present\n        # but reward funcs normally receive only the generated assistant message as one-item list\n        if sample and isinstance(sample[0], dict) and \"content\" in sample[0]:\n            return sample[0][\"content\"]\n        return \"\\n\".join(_as_text(x) for x in sample)\n    return str(sample)\n\n#extracting prompts for parser: try to get needed information for rewards from prompts (can be addded individually by providing **kwargs to functions) \n#(only prompts from latest benchmark_version chosen=1.6v)\ndef _get_prompt_texts(kwargs: Dict[str, Any]) -> List[str]:\n    \"\"\"Try to pull original prompts per sample, tolerant to TRL variants.\"\"\"\n    prompts = kwargs.get(\"prompts\") or kwargs.get(\"prompt\") or kwargs.get(\"queries\")\n    if not prompts:\n        return []\n    out = []\n    for p in prompts:\n        if isinstance(p, str):\n            out.append(p)\n        elif isinstance(p, list):\n            # conversational messages\n            # pick the last user/developer/system chunk content as the prompt text surrogate\n            parts = []\n            for msg in p:\n                if isinstance(msg, dict) and \"content\" in msg:\n                    parts.append(msg[\"content\"])\n            out.append(\"\\n\".join(parts))\n        elif isinstance(p, dict) and \"content\" in p:\n            out.append(p[\"content\"])\n        else:\n            out.append(str(p))\n    return out\n\n#normalization\ndef _norm(s: str) -> str:\n    return re.sub(r\"\\s+\", \" \", s).strip().lower()\n\n#clip/constrain rewards\ndef _clip(x: float, lo=-1.0, hi=1.0) -> float:\n    return max(lo, min(hi, x))\n\ndef _starts_with_tag(text: str, tag: str) -> bool:\n    return _norm(text).startswith(tag.lower())\n\n#search\ndef _contains(text: str, key: str) -> bool:\n    return key.lower() in text.lower()\n\n#tokenize\ndef _tokenize(s: str) -> List[str]:\n    return re.findall(r\"[a-zA-Z']+\", s.lower())\n\n#count useful words (for taboo: brief+substancial)\ndef _count_content_words(s: str) -> int:\n    toks = _tokenize(s)\n    stop = {\"the\",\"a\",\"an\",\"and\",\"or\",\"but\",\"if\",\"then\",\"so\",\"to\",\"of\",\"for\",\"in\",\"on\",\"at\",\"by\",\"with\",\"as\",\"is\",\"are\",\"be\"}\n    return sum(1 for t in toks if t not in stop and len(t) > 2)\n\n# ------------------------------ grid helpers ------------------------------\n\n#converts ascii grid to lists\ndef _parse_grid_block(block: str) -> List[List[str]]:\n    \"\"\"\n    Parse a 5x5 grid written with tokens like '▢' or letters ('X','S',...).\n    Returns matrix[5][5] (strings).\n    \"\"\"\n    lines = [ln.strip() for ln in block.strip().splitlines() if ln.strip()]\n    # accept compact \"▢ ▢ X ...\" style\n    grid = []\n    for ln in lines:\n        cells = ln.split()\n        # handle lines without spaces (unlikely here)\n        if len(cells) == 1 and len(cells[0]) >= 5:\n            cells = list(cells[0])\n        grid.append(cells)\n    # best effort to 5x5\n    grid = [row[:5] + [\"▢\"]*(5-len(row)) for row in grid[:5]]\n    if len(grid) < 5:\n        grid += [[\"▢\"]*5 for _ in range(5-len(grid))]\n    return grid\n\n#compute matching of cells\ndef _grid_equal(a: List[List[str]], b: List[List[str]]) -> bool:\n    return all(a[r][c] == b[r][c] for r in range(5) for c in range(5))\n\n#compute matching of cells\ndef _grid_match_count(a: List[List[str]], b: List[List[str]]) -> int:\n    return sum(1 for r in range(5) for c in range(5) if a[r][c] == b[r][c])\n\ndef _empty_grid() -> List[List[str]]:\n    return [[\"▢\"]*5 for _ in range(5)]\n\n#understands some simple instructions\ndef _apply_instruction(grid: List[List[str]], instr: str) -> None:\n    \"\"\"\n    Apply a small subset of supported commands:\n    - \"Put an E in second row third column\"\n    - \"Put a X in 5th row 1st column\"\n    - \"Fill the last row with X\"\n    - \"Fill the 2nd column with S\"\n    \"\"\"\n    s = _norm(instr)\n    # Put an <L> in <row> row <col> column\n    m = re.search(r\"put (?:an|a)\\s+([a-z])\\s+in\\s+(first|second|third|fourth|fifth|last|[1-5]|[0-9]+)\\s+row\\s+(first|second|third|fourth|fifth|last|[1-5]|[0-9]+)\\s+column\", s)\n    if m:\n        L = m.group(1).upper()\n        r_tok, c_tok = m.group(2), m.group(3)\n        r = ORD2IDX.get(r_tok, None)\n        c = ORD2IDX.get(c_tok, None)\n        if r is None and r_tok.isdigit(): r = max(0, min(4, int(r_tok)-1))\n        if c is None and c_tok.isdigit(): c = max(0, min(4, int(c_tok)-1))\n        if r is not None and c is not None:\n            grid[r][c] = L\n        return\n\n    # Fill the <row/column> with <L>\n    m = re.search(r\"fill the\\s+(first|second|third|fourth|fifth|last|[1-5])\\s+(row|column)\\s+with\\s+([a-z])\", s)\n    if m:\n        pos_tok, axis, L = m.group(1), m.group(2), m.group(3).upper()\n        idx = ORD2IDX.get(pos_tok, None)\n        if idx is None and pos_tok.isdigit():\n            idx = max(0, min(4, int(pos_tok)-1))\n        if idx is None: \n            return\n        if axis == \"row\":\n            for c in range(5): grid[idx][c] = L\n        else:\n            for r in range(5): grid[r][idx] = L\n        return\n    # otherwise: ignore (reward will not improve)\n\n# ------------------------------ WORDLE core ------------------------------\n\ndef _extract_guess(text: str) -> str | None:\n    m = re.search(r\"(?im)^\\s*guess:\\s*([a-z]{5})\\s*$\", text)\n    return m.group(1) if m else None\n\ndef _extract_explanation(text: str) -> str:\n    m = re.search(r\"(?is)explanation:\\s*(.+)$\", text)\n    return m.group(1).strip() if m else \"\"\n\n#penalizes self-invented feedback\ndef _has_fabricated_feedback(text: str) -> bool:\n    return bool(re.search(r\"(?i)guess_feedback\\s*:\", text))\n\n#(green letters=1, yellow= 0.5, normalized by diving by 5)\ndef _wordle_score_from_target(guess: str, target: str) -> float:\n    \"\"\"Score in [0,1]: 1 for exact, else greens=1/5, yellows=0.5/5.\"\"\"\n    greens = sum(g == t for g, t in zip(guess, target))\n    # yellows: count letters in both minus greens, capped by target letter counts\n    from collections import Counter\n    gC, tC = Counter(guess), Counter(target)\n    common = sum(min(gC[ch], tC[ch]) for ch in gC)\n    yellows = max(0, common - greens)\n    return _clip((greens + 0.5*yellows) / 5.0, 0.0, 1.0)\n\ndef _parse_feedback_string(s: str) -> List[tuple[str,str]]:\n    \"\"\"Parse 'a<yellow> p<green> ...' -> [(a,'yellow'), (p,'green'), ...]\"\"\"\n    pairs = []\n    for m in re.finditer(r\"([a-z])\\s*<\\s*(green|yellow|red)\\s*>\", s, re.I):\n        pairs.append((m.group(1).lower(), m.group(2).lower()))\n    return pairs\n\n# ------------------------------ REFERENCEGAME helpers ------------------------------\n\ndef _rows_full_of_X(grid): return {r for r in range(5) if all(cell.upper()==\"X\" for cell in grid[r])}\ndef _cols_full_of_X(grid): return {c for c in range(5) if all(grid[r][c].upper()==\"X\" for r in range(5))}\ndef _main_diag_full_X(grid): return all(grid[i][i].upper()==\"X\" for i in range(5))\ndef _anti_diag_full_X(grid): return all(grid[i][4-i].upper()==\"X\" for i in range(5))\n\n#extracts target/distractors from prompt\ndef _parse_three_grids_from_prompt(prompt_text: str):\n    # Expect \"Target grid:\" ... \"\\n\\nDistractor grid 1:\" ... \"\\n\\nDistractor grid 2:\"\n    parts = re.split(r\"(?i)distractor grid\\s*1\\s*:\\s*\", prompt_text)\n    tgt_block = parts[0]\n    rest = parts[1] if len(parts) > 1 else \"\"\n    parts2 = re.split(r\"(?i)distractor grid\\s*2\\s*:\\s*\", rest)\n    d1_block = parts2[0] if len(parts2)>0 else \"\"\n    d2_block = parts2[1] if len(parts2)>1 else \"\"\n    # trim headers\n    tgt = _parse_grid_block(re.split(r\"(?i)target grid\\s*:\\s*\", tgt_block)[-1])\n    d1 = _parse_grid_block(d1_block)\n    d2 = _parse_grid_block(d2_block)\n    return tgt, d1, d2\n\n#remembers full/no more space rows of grid\ndef _grids_features(grid):\n    return {\n        \"rows_full\": _rows_full_of_X(grid),\n        \"cols_full\": _cols_full_of_X(grid),\n        \"main_diag\": _main_diag_full_X(grid),\n        \"anti_diag\": _anti_diag_full_X(grid),\n    }\n\n#extracts contraints out of the explanation    \ndef _expression_constraints(expr: str):\n    \"\"\"Extract simple constraints like 'third row full', 'second column full'.\"\"\"\n    s = _norm(expr)\n    constraints = []\n    for m in re.finditer(r\"(first|second|third|fourth|fifth|last|[1-5]|top|bottom|leftmost|rightmost|middle|center)\\s+(row|column|col)\", s):\n        ord_tok, axis = m.group(1), \"column\" if \"col\" in m.group(2) else m.group(2)\n        idx = ORD2IDX.get(ord_tok, None)\n        if idx is None and ord_tok.isdigit(): idx = int(ord_tok)-1\n        if idx is not None:\n            constraints.append((\"row_full\" if axis==\"row\" else \"col_full\", idx))\n    # diagonals\n    if \"main diagonal\" in s or \"primary diagonal\" in s or \"top-left to bottom-right\" in s:\n        constraints.append((\"main_diag\", True))\n    if \"anti diagonal\" in s or \"secondary diagonal\" in s or \"top-right to bottom-left\" in s:\n        constraints.append((\"anti_diag\", True))\n    return constraints\n\ndef _satisfies(grid_feats, constraints):\n    for kind, val in constraints:\n        if kind==\"row_full\":\n            if val not in grid_feats[\"rows_full\"]: return False\n        elif kind==\"col_full\":\n            if val not in grid_feats[\"cols_full\"]: return False\n        elif kind==\"main_diag\":\n            if not grid_feats[\"main_diag\"]: return False\n        elif kind==\"anti_diag\":\n            if not grid_feats[\"anti_diag\"]: return False\n    return True\n\n# ------------------------------ TABOO helpers ------------------------------\n\n#reads target word + related words\ndef _parse_taboo_from_prompt(prompt_text: str):\n    # Extract target and related words sections from the provided prompt text\n    tgt_m = re.search(r\"This is the target word.*?:\\s*([\\s\\S]*?)\\n\\nRelated words\", prompt_text, re.I)\n    target = (tgt_m.group(1).strip() if tgt_m else \"\").splitlines()[0].strip().strip(\".\")\n    related_block = re.search(r\"Related words are:\\s*([\\s\\S]*?)\\n\\nImportant:\", prompt_text, re.I)\n    related = []\n    if related_block:\n        for line in related_block.group(1).splitlines():\n            m = re.search(r\"-\\s*(\\S+)\", line)\n            if m: related.append(m.group(1).strip())\n    return target, related\n\n#checks for forbidden usage of target/related words in text\ndef _badword_hit(clue: str, banned: List[str]) -> bool:\n    clue_l = clue.lower()\n    toks = _tokenize(clue)\n    for w in banned:\n        w = w.lower()\n        if w in toks:\n            return True\n        # crude morphological / possessive / hyphen variants\n        if re.search(rf\"\\b{re.escape(w)}(?:'s|s|ed|ing|er|ers|ly)?\\b\", clue_l):\n            return True\n        if w in clue_l.replace(\"-\", \" \"):  # inside hyphenated compounds\n            return True\n    return False\n\n\n#-----------------------------REWARD FUNCTIONS------------------------------------\n\n# ------------------------------ 1) IMAGEGAME ------------------------------\n\n\"\"\"\nIdea: We simulate what the model’s Instruction: lines would do to a start grid and measure the progress toward a target grid.\n\nHow it works:\n\nTarget grid is taken from kwargs[\"target_grid\"] or parsed from the prompt (the block at the end of the imagegame prompt).\nStart grid defaults to empty (or kwargs[\"start_grid\"] if provided).\n\nWe collect all lines matching Instruction: … from the model output.\n\nFor each instruction, we apply it to a working copy of the grid using _apply_instruction, which supports:\n\nplacing a single letter at a (row, column) location, e.g.\n“Put an E in second row third column”\n\nfilling a whole row/column with a letter, e.g.\n“Fill the fifth row with X”\n\nWe compute before/after matches against the target: number of identical cells (0..25).\n\nScoring:\n\nFormat bonus: +0.1 if at least one Instruction: is present.\n\nProgress: +(matches_after − matches_before)/25.\n\nDONE handling: If the output contains DONE:\n\n+0.2 only if the grid exactly equals the target;\n\notherwise -0.2 (premature completion).\n\nFinal reward is clipped to [-1, 1].\n\nExample: If the grid improves from 10 to 18 correct cells, delta = 8 → 8/25 ≈ 0.32. With format +0.1, total ≈ 0.42. If DONE and exact match, add +0.2 → 0.62.\n\nLimitations: _apply_instruction covers the most common phrasing patterns (place single cell; fill full row/column). Freer language may be ignored (no error, just no progress).\n\"\"\"\n\n\ndef reward_imagegame(completions: List[Any], **kwargs) -> List[float]:\n    \"\"\"\n    Reward = normalized improvement toward target grid by executing the model's \"Instruction:\" lines.\n      + format bonuses for correct \"Instruction:\" usage\n      + correctness for 'DONE' only when grid fully matches target\n    Needs target grid; will parse from prompt if possible. If not found, falls back to format reward.\n    Optional kwargs:\n      - target_grid: str (5x5 text)\n      - start_grid: str (default = empty grid)\n    \"\"\"\n    prompts = _get_prompt_texts(kwargs)\n    target_grid_text = kwargs.get(\"target_grid\")\n    start_grid_text = kwargs.get(\"start_grid\")\n\n    # Try to infer target grid from imagegame prompt if missing\n    if not target_grid_text and prompts:\n        # Use the last grid block in the prompt (after \"Ok. Please do this for the following example\")\n        pm = re.split(r\"Ok\\.\\s*Please do this.*?\\n\", prompts[0], flags=re.I|re.S)\n        if len(pm) > 1:\n            target_grid_text = pm[-1]\n        else:\n            # else: grab the last 5 lines containing '▢' or letters\n            lines = [ln for ln in prompts[0].splitlines() if \"▢\" in ln or re.search(r\"[A-Za-z]\", ln)]\n            target_grid_text = \"\\n\".join(lines[-5:]) if len(lines) >= 5 else None\n\n    tgt = _parse_grid_block(target_grid_text) if target_grid_text else None\n    cur = _parse_grid_block(start_grid_text) if start_grid_text else _empty_grid()\n\n    rewards = []\n    for i, comp in enumerate(completions):\n        text = _as_text(comp)\n        done_declared = bool(re.search(r\"(?i)\\bDONE\\b\", text))\n        instrs = re.findall(r\"(?im)^\\s*Instruction:\\s*(.+)$\", text)\n        if not instrs and not tgt:\n            # no target => only format compliance\n            rewards.append(0.2 if _contains(text, \"Instruction:\") else 0.0)\n            continue\n\n        local_tgt = tgt\n        # (allow per-sample prompt override if provided)\n        if not local_tgt and prompts:\n            # best effort per-sample\n            local_tgt = _empty_grid()\n\n        before = _grid_match_count(cur, local_tgt) if local_tgt else 0\n        grid_tmp = [row[:] for row in cur]\n\n        for ins in instrs:\n            _apply_instruction(grid_tmp, ins)\n\n        after = _grid_match_count(grid_tmp, local_tgt) if local_tgt else before\n        delta = after - before\n        # normalize by 25 cells, plus format bonus for valid instructions\n        r = 0.0\n        if instrs:\n            r += 0.1\n        r += (delta / 25.0)\n        if done_declared:\n            if local_tgt and _grid_equal(grid_tmp, local_tgt):\n                r += 0.2\n            else:\n                r -= 0.2  # premature DONE\n        rewards.append(_clip(r))\n    return rewards\n\n# ------------------------------ 2) REFERENCEGAME ------------------------------\n\n\"\"\"\nIdea: Reward a referring expression that uniquely identifies the target grid against two distractors, using robust, easily parsed features: “row full of X”, “column full of X”, “main/anti diagonal full of X”.\n\nHow it works:\n\nParse the target and two distractor grids from the prompt (or from kwargs).\n\nStrip the leading tag and read the expression after Expression:.\n\nExtract constraints with _expression_constraints, e.g.:\n\n(\"row_full\", 2) for “third row full”\n\n(\"col_full\", 1) for “second column full”\n\n(\"main_diag\", True), (\"anti_diag\", True)\n\nCompute, for each grid, whether it satisfies all constraints.\n\nScoring:\n\nTag bonus: +0.2 if the output starts with Expression:.\n\nUniqueness:\n\n+0.8 if only the target satisfies the constraints;\n\n+0.3 if constraints are ambiguous (>=2 grids match) but the target is among them;\n\n0.0 otherwise.\n\nClip to [-1, 1].\n\nExample: Target has the third row fully X; distractors have first and second rows fully X. Expression “third row is fully X” → unique → 0.2 + 0.8 = 1.0.\n\nLimitations: We score “full rows/columns/diagonals.” For more complex shapes (L-shapes, borders, counts), extend both the constraint extractor and the feature set.\n\n\"\"\"\n\ndef reward_referencegame(completions: List[Any], **kwargs) -> List[float]:\n    \"\"\"\n    Reward if 'Expression: ...' uniquely identifies the target grid among two distractors.\n    Parsing: tries to read the 3 grids from the prompt (or kwargs: target_grid, distractor1, distractor2).\n    Constraints extracted: 'third row', 'second column', diagonals. We check 'full of X'.\n    Rewards:\n      +0.2 correct tag 'Expression:'\n      +0.8 if constraints select only the target; +0.3 if ambiguous but includes a *true* target feature; 0 otherwise.\n    \"\"\"\n    prompts = _get_prompt_texts(kwargs)\n    t_text = kwargs.get(\"target_grid\")\n    d1_text = kwargs.get(\"distractor1\")\n    d2_text = kwargs.get(\"distractor2\")\n\n    if (not t_text or not d1_text or not d2_text) and prompts:\n        try:\n            t, d1, d2 = _parse_three_grids_from_prompt(prompts[0])\n        except Exception:\n            t = d1 = d2 = None\n    else:\n        t = _parse_grid_block(t_text) if t_text else None\n        d1 = _parse_grid_block(d1_text) if d1_text else None\n        d2 = _parse_grid_block(d2_text) if d2_text else None\n\n    rewards = []\n    for comp in completions:\n        text = _as_text(comp)\n        tag_bonus = 0.2 if _starts_with_tag(text, \"expression:\") else 0.0\n        expr = re.sub(r\"(?i)^expression:\\s*\", \"\", text).strip()\n\n        if not (t and d1 and d2):\n            # no grids available: only format reward\n            rewards.append(tag_bonus)\n            continue\n\n        feats = [_grids_features(g) for g in (t, d1, d2)]\n        constraints = _expression_constraints(expr)\n\n        # If no explicit constraint extracted, try a simple heuristic for rows 'full of X' mentioned as \"row 3 all X\"\n        if not constraints:\n            m = re.search(r\"(first|second|third|fourth|fifth|last|[1-5]).*?(row).*?(all|full).*?x\", _norm(expr))\n            if m:\n                idx = ORD2IDX.get(m.group(1), None)\n                if idx is None and m.group(1).isdigit(): idx = int(m.group(1))-1\n                if idx is not None:\n                    constraints = [(\"row_full\", idx)]\n\n        matches = [ _satisfies(f, constraints) for f in feats ] if constraints else [False, False, False]\n\n        score = 0.0\n        if any(matches):\n            if matches == [True, False, False]:\n                score = 0.8\n            elif matches.count(True) == 1 and matches[0]:\n                score = 0.8\n            elif matches.count(True) > 1:\n                # ambiguous, but maybe constraints do match a target-only feature?\n                # award small partial if target does match at least one true feature that distractors lack\n                score = 0.3\n        rewards.append(_clip(tag_bonus + score))\n    return rewards\n\n# ------------------------------ 3) TABOO ------------------------------\n\n\"\"\"\nIdea: Reward exactly one CLUE: … line that does not use prohibited words (the target and related words, including simple morphological variants), and that is short yet meaningful.\n\nHow it works:\n\nParse target and related words from the prompt (or use kwargs[\"target\"], kwargs[\"related_words\"]).\n\nExtract exactly one CLUE: line.\n\nCheck for banned words and simple variations (possessive 's, plural s, -ed, -ing, hyphenated forms, etc.).\n\nScoring:\n\n+0.3 if the format is correct (CLUE: at line start).\n\n+0.4 if no banned words (else -0.4).\n\n+0.2 for brevity & substance: 2–12 tokens and at least 2 content words.\n\n-0.3 if there are multiple CLUE: lines or if GUESS: appears (extra chatter).\n\nClip to [-1, 1].\n\nExample:\nCLUE: opposite of yes\nFormat +0.3, no taboo hits +0.4, 3 tokens with ≥2 content words +0.2 → 0.9 total.\n\nEdge cases: The morphology check is lightweight; for heavy-inflection languages, you may want a stronger normalizer.\n\"\"\"\n\ndef reward_taboo(completions: List[Any], **kwargs) -> List[float]:\n    \"\"\"\n    Rewards a *single* CLUE line that obeys taboo rules and is concise.\n    Sources:\n      - target, related words parsed from prompt, or kwargs: target, related_words (list[str])\n    Scoring:\n      +0.3 correct format 'CLUE: ...'\n      +0.4 safe: no target/related words (incl. simple morphological variants)\n      +0.2 brevity & substance: 2..12 words and >=2 content words\n      -0.3 if includes 'GUESS:' or multiple clues or extra chatter\n    \"\"\"\n    prompts = _get_prompt_texts(kwargs)\n    target = kwargs.get(\"target\")\n    related = kwargs.get(\"related_words\")\n\n    if (not target or not related) and prompts:\n        tgt, rel = _parse_taboo_from_prompt(prompts[0])\n        target = target or tgt\n        related = related or rel or []\n\n    banned = [w for w in ([target] + (related or [])) if w]\n\n    rewards = []\n    for comp in completions:\n        text = _as_text(comp)\n        clue_lines = re.findall(r\"(?im)^\\s*CLUE:\\s*(.+)$\", text)\n        r = 0.0\n        if clue_lines:\n            r += 0.3\n            clue = clue_lines[0].strip()\n            # safety\n            if banned and not _badword_hit(clue, banned):\n                r += 0.4\n            elif banned:\n                r -= 0.4\n            # brevity + substance\n            wc = len(_tokenize(clue))\n            if 2 <= wc <= 12 and _count_content_words(clue) >= 2:\n                r += 0.2\n        else:\n            # no 'CLUE:' prefix → zero by default\n            r += 0.0\n\n        # penalties\n        if len(clue_lines) > 1 or _contains(text, \"GUESS:\"):\n            r -= 0.3\n\n        rewards.append(_clip(r))\n    return rewards\n\n# ------------------------------ 4) WORDLE (base) ------------------------------\n\"\"\"\nIdea: Reward correct format and the quality of the five-letter guess. Quality comes either from a known target (best supervision) or from provided feedback tokens when the target is unknown.\n\nScoring breakdown:\n\nFormat:\n\n+0.2 if guess: with a 5-letter token is present.\n\n+0.1 if explanation: is present.\n\n+0.1 if the guess matches [a-z]{5} (formal validity).\n\n-0.2 if the model fabricates a guess_feedback: line (forbidden).\n\nContent (up to +0.6):\n\nIf target is provided:\n_wordle_score_from_target(guess, target) where\nscore = (greens + 0.5 * yellows) / 5 in [0,1]. Multiply by 0.6.\n\nElse if feedback is provided:\nParse a<yellow> p<green> ...; compute (greens + 0.5*yellows)/5 * 0.6.\n\nFinally, clip to [-1, 1].\n\nBroadcasting labels: If you pass a scalar target/feedback, it’s broadcast to the whole batch for convenience.\n\nExample (with target “crane”):\nGuess caper: suppose greens=2, yellows=1 → (2 + 0.5)/5 = 0.5; content 0.6*0.5=0.3.\nFormat (+0.2 +0.1 +0.1) → 0.4. Total ≈ 0.7 (assuming no fabricated feedback).\n\"\"\"\n\n\ndef reward_wordle(completions: List[Any], **kwargs) -> List[float]:\n    \"\"\"\n    Scores a single Wordle guess for:\n      - correct format 'guess:' (+0.2) and 'explanation:' (+0.1)\n      - valid 5-letter word (+0.1)\n      - NO fabricated 'guess_feedback:' (−0.2)\n      - semantic score from target or from provided feedback (greens 1.0, yellows 0.5; normalized to [0,1])\n    Optional kwargs per sample (lists or scalars):\n      - target: str (the secret word)  -> strongest supervision\n      - feedback: str like 'a<yellow> p<green> ...' -> partial supervision\n    Also accepts parsing the clue from prompt for the _withclue/_withcritic variants (but plain wordle ignores clue).\n    \"\"\"\n    # broadcast scalar kwargs to per-sample lists\n    def _as_list(v, n): return [v]*n if (v is not None and not isinstance(v, (list, tuple))) else (v or [None]*n)\n    N = len(completions)\n\n    targets = _as_list(kwargs.get(\"target\"), N)\n    feedbacks = _as_list(kwargs.get(\"feedback\"), N)\n\n    rewards = []\n    for i, comp in enumerate(completions):\n        text = _as_text(comp)\n        guess = _extract_guess(text)\n        expl  = _extract_explanation(text)\n\n        r = 0.0\n        if guess: r += 0.2\n        if expl:  r += 0.1\n        if guess and re.fullmatch(r\"[a-z]{5}\", guess): r += 0.1\n        if _has_fabricated_feedback(text): r -= 0.2\n\n        # target-based scoring\n        if targets[i] and guess:\n            r += 0.6 * _wordle_score_from_target(guess, targets[i].lower())\n        # feedback-based scoring (we don't know the target)\n        elif feedbacks[i] and guess:\n            pairs = _parse_feedback_string(feedbacks[i])\n            greens = sum(1 for (ch, col) in pairs if col == \"green\")\n            yellows = sum(1 for (ch, col) in pairs if col == \"yellow\")\n            # normalize by 5\n            r += 0.6 * _clip((greens + 0.5*yellows)/5.0, 0.0, 1.0)\n\n        rewards.append(_clip(r))\n    return rewards\n\n# ------------------------------ 5) WORDLE with CLUE ------------------------------\n\"\"\"\nAdd-on to base Wordle: The explanation should actually use the clue.\n\nHow it works:\n\nParse the clue from the prompt (or kwargs[\"clue\"]), tokenize to meaningful tokens.\n\nAdd +0.2 if the explanation contains at least one non-trivial clue token.\n\nAll the base Wordle scoring (format, content via target or feedback, anti-hallucination) still applies.\n\nExample:\nClue: others’. If the explanation references possessives/ownership or literally includes a matching token, add +0.2.\n\"\"\"\n\n\ndef reward_wordle_withclue(completions: List[Any], **kwargs) -> List[float]:\n    \"\"\"\n    Same as reward_wordle, plus reward for USING the given clue in explanation:\n      +0.2 if explanation references at least one non-stopword token from the clue.\n    Clue is parsed from prompt if not in kwargs['clue'].\n    \"\"\"\n    prompts = _get_prompt_texts(kwargs)\n    clue = kwargs.get(\"clue\")\n    if not clue and prompts:\n        m = re.search(r\"(?im)^\\s*clue\\s*:\\s*(.+)$\", prompts[0])\n        clue = m.group(1).strip() if m else None\n\n    base = reward_wordle(completions, **kwargs)  # includes target/feedback handling if provided\n    clue_tokens = set(t for t in _tokenize(clue or \"\") if len(t) > 2)\n\n    out = []\n    for r, comp in zip(base, completions):\n        text = _as_text(comp)\n        expl = _extract_explanation(text)\n        bonus = 0.0\n        if clue_tokens and any(tok in _tokenize(expl) for tok in clue_tokens):\n            bonus += 0.2\n        out.append(_clip(r + bonus))\n    return out\n\n# ------------------------------ 6) WORDLE with CRITIC ------------------------------\n\"\"\"\nAdd-on to “withclue”: Make the model reflect the critic’s agreement/disagreement and adapt its guess if the critic disagreed.\n\nInputs:\n\ncritic_agreement ∈ { 'agree', 'disagree', True, False } (scalar or per-sample).\n\nprior_guess (optional) — the previous guess to detect adaptation.\n\nBonuses:\n\n+0.15 if the explanation explicitly references agree/disagree in line with critic_agreement.\n\n+0.10 if critic_agreement == 'disagree' and the new guess differs from prior_guess.\n\nPlus the full reward from reward_wordle_withclue.\n\nExample:\nCritic: “disagree”, prior guess apple, new guess angle. Explanation mentions disagreement → +0.15; changed guess → +0.10. Add to the with-clue/base score.\n\"\"\"\n\n\ndef reward_wordle_withcritic(completions: List[Any], **kwargs) -> List[float]:\n    \"\"\"\n    Wordle + critic-awareness:\n      - Base wordle reward (target/feedback if provided)\n      - +0.15 if explanation explicitly references 'agree'/'disagree' consistent with kwargs['critic_agreement'] ∈ {'agree','disagree', True/False}\n      - +0.10 if critic disagreed and the model changed guess compared to kwargs['prior_guess']\n    Clue handling like wordle_withclue (optional).\n    \"\"\"\n    base = reward_wordle_withclue(completions, **kwargs)\n\n    def norm_agree(v) -> str | None:\n        if isinstance(v, bool): return \"agree\" if v else \"disagree\"\n        if isinstance(v, str):\n            v = v.strip().lower()\n            if v in {\"agree\",\"agreed\"}: return \"agree\"\n            if v in {\"disagree\",\"disagreed\",\"reject\"}: return \"disagree\"\n        return None\n\n    N = len(completions)\n    critic = kwargs.get(\"critic_agreement\")\n    critic_list = [norm_agree(critic)]*N if not isinstance(critic, (list,tuple)) else [norm_agree(x) for x in critic]\n    prior_guess = kwargs.get(\"prior_guess\")\n    prior_list = [prior_guess]*N if not isinstance(prior_guess, (list,tuple)) else list(prior_guess)\n\n    out = []\n    for i, (r, comp) in enumerate(zip(base, completions)):\n        text = _as_text(comp)\n        expl = _extract_explanation(text)\n        guess = _extract_guess(text)\n        bonus = 0.0\n\n        if critic_list[i]:\n            wants = critic_list[i]\n            if wants == \"agree\" and re.search(r\"(?i)\\bagree\\b\", expl):\n                bonus += 0.15\n            if wants == \"disagree\" and re.search(r\"(?i)\\bdisagree|\\bnot\\b\\s+agree\", expl):\n                bonus += 0.15\n\n        if critic_list[i] == \"disagree\" and prior_list[i]:\n            # reward adapting the guess\n            if guess and guess != str(prior_list[i]).lower():\n                bonus += 0.10\n\n        out.append(_clip(r + bonus))\n    return out\n\n# ------------------------------ wiring helper ------------------------------\n\"\"\"\nA tiny convenience map from a game name string to the corresponding reward function:\n{'imagegame','referencegame','taboo','wordle','wordle_withclue','wordle_withcritic'}\n\"\"\"\n\ndef get_reward_fn_by_game(name: str):\n    \"\"\"\n    Convenience selector.\n    name ∈ {'imagegame','referencegame','taboo','wordle','wordle_withclue','wordle_withcritic'}\n    \"\"\"\n    name = (name or \"\").lower()\n    return {\n        \"imagegame\": reward_imagegame,\n        \"referencegame\": reward_referencegame,\n        \"taboo\": reward_taboo,\n        \"wordle\": reward_wordle,\n        \"wordle_withclue\": reward_wordle_withclue,\n        \"wordle_withcritic\": reward_wordle_withcritic,\n    }.get(name)","metadata":{"_uuid":"d3f107f3-cf64-45f6-a9a0-b993830673ee","_cell_guid":"d1c291a6-d285-4042-8d40-661078da4552","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-19T11:32:56.642576Z","iopub.execute_input":"2025-08-19T11:32:56.644072Z","iopub.status.idle":"2025-08-19T11:32:56.752268Z","shell.execute_reply.started":"2025-08-19T11:32:56.643990Z","shell.execute_reply":"2025-08-19T11:32:56.750597Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"f754c15c-a0f8-402b-a1fe-8ddf7d9e5f1a","_cell_guid":"598242af-b624-4e24-a386-6570b739369c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}